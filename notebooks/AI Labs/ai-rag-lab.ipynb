{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Lab Documentation and Solutions](https://img.shields.io/badge/Lab%20Documentation%20and%20Solutions-purple)](https://mongodb-developer.github.io/ai-rag-lab/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Setup prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ok': 1.0,\n",
       " '$clusterTime': {'clusterTime': Timestamp(1745417194, 1),\n",
       "  'signature': {'hash': b'\\xb4\\xe4c\\xe9}\\xc1\\x1f\\xees\\x9e\\xb4\\xae\\x02\\x1dJ%\\xabA\\x8dA',\n",
       "   'keyId': 7496241214685970439}},\n",
       " 'operationTime': Timestamp(1745417194, 1)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MONGODB_URI = \"mongodb://admin:mongodb@mongodb:27017/\"\n",
    "# Initialize a MongoDB Python client\n",
    "mongodb_client = MongoClient(MONGODB_URI, appname=\"devrel.workshop.rag\")\n",
    "# Check the connection to the server\n",
    "mongodb_client.admin.command(\"ping\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Do not change the values assigned to the variables below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database name\n",
    "DB_NAME = \"mongodb_genai_devday_rag\"\n",
    "# Collection name\n",
    "COLLECTION_NAME = \"knowledge_base\"\n",
    "# Name of the vector search index\n",
    "ATLAS_VECTOR_SEARCH_INDEX_NAME = \"vector_index\"\n",
    "# URL of the serverless function\n",
    "SERVERLESS_URL = os.environ.get(\"SERVERLESS_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVERLESS_URL = os.environ.get(\"SERVERLESS_URL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may see a warning upon running this cell. You can ignore it.\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "259ef97979ec4bccb43ce6f46a4a06b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/2.01k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f8fa55cb49419f911470cffd96a26c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "mongodb_docs.json:   0%|          | 0.00/86.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c17e7f53c69144398d79d905a195bda6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download the `mongodb-docs` dataset from Hugging Face\n",
    "data = load_dataset(\"mongodb/mongodb-docs\", split=\"train\")\n",
    "# Convert the dataset into a dataframe first, then into a list of Python objects/dictionaries\n",
    "docs = pd.DataFrame(data).to_dict(\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note the number of documents in the dataset\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updated': '2024-05-20T17:30:49.148Z',\n",
       " 'metadata': {'contentType': None,\n",
       "  'productName': 'MongoDB Atlas',\n",
       "  'tags': ['atlas', 'docs'],\n",
       "  'version': None},\n",
       " 'action': 'created',\n",
       " 'sourceName': 'snooty-cloud-docs',\n",
       " 'body': '# View Database Access History\\n\\n- This feature is not available for `M0` free clusters, `M2`, and `M5` clusters. To learn more, see Atlas M0 (Free Cluster), M2, and M5 Limits.\\n\\n- This feature is not supported on Serverless instances at this time. To learn more, see Serverless Instance Limitations.\\n\\n## Overview\\n\\nAtlas parses the MongoDB database logs to collect a list of authentication requests made against your clusters through the following methods:\\n\\n- `mongosh`\\n\\n- Compass\\n\\n- Drivers\\n\\nAuthentication requests made with API Keys through the Atlas Administration API are not logged.\\n\\nAtlas logs the following information for each authentication request within the last 7 days:\\n\\n<table>\\n<tr>\\n<th id=\"Field\">\\nField\\n\\n</th>\\n<th id=\"Description\">\\nDescription\\n\\n</th>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nTimestamp\\n\\n</td>\\n<td headers=\"Description\">\\nThe date and time of the authentication request.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nUsername\\n\\n</td>\\n<td headers=\"Description\">\\nThe username associated with the database user who made the authentication request.\\n\\nFor LDAP usernames, the UI displays the resolved LDAP name. Hover over the name to see the full LDAP username.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nIP Address\\n\\n</td>\\n<td headers=\"Description\">\\nThe IP address of the machine that sent the authentication request.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nHost\\n\\n</td>\\n<td headers=\"Description\">\\nThe target server that processed the authentication request.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nAuthentication Source\\n\\n</td>\\n<td headers=\"Description\">\\nThe database that the authentication request was made against. `admin` is the authentication source for SCRAM-SHA users and `$external` for LDAP users.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nAuthentication Result\\n\\n</td>\\n<td headers=\"Description\">\\nThe success or failure of the authentication request. A reason code is displayed for the failed authentication requests.\\n\\n</td>\\n</tr>\\n</table>Authentication requests are pre-sorted by descending timestamp with 25 entries per page.\\n\\n### Logging Limitations\\n\\nIf a cluster experiences an activity spike and generates an extremely large quantity of log messages, Atlas may stop collecting and storing new logs for a period of time.\\n\\nLog analysis rate limits apply only to the Performance Advisor UI, the Query Insights UI, the Access Tracking UI, and the Atlas Search Query Analytics UI. Downloadable log files are always complete.\\n\\nIf authentication requests occur during a period when logs are not collected, they will not appear in the database access history.\\n\\n## Required Access\\n\\nTo view database access history, you must have `Project Owner` or `Organization Owner` access to Atlas.\\n\\n## Procedure\\n\\n<Tabs>\\n\\n<Tab name=\"Atlas CLI\">\\n\\nTo return the access logs for a cluster using the Atlas CLI, run the following command:\\n\\n```sh\\n\\natlas accessLogs list [options]\\n\\n```\\n\\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas accessLogs list.\\n\\n- Install the Atlas CLI\\n\\n- Connect to the Atlas CLI\\n\\n</Tab>\\n\\n<Tab name=\"Atlas Administration API\">\\n\\nTo view the database access history using the API, see Access Tracking.\\n\\n</Tab>\\n\\n<Tab name=\"Atlas UI\">\\n\\nUse the following procedure to view your database access history using the Atlas UI:\\n\\n### Navigate to the Clusters page for your project.\\n\\n- If it is not already displayed, select the organization that contains your desired project from the  Organizations menu in the navigation bar.\\n\\n- If it is not already displayed, select your desired project from the Projects menu in the navigation bar.\\n\\n- If the Clusters page is not already displayed, click Database in the sidebar.\\n\\n### View the cluster\\'s database access history.\\n\\n- On the cluster card, click .\\n\\n- Select View Database Access History.\\n\\nor\\n\\n- Click the cluster name.\\n\\n- Click .\\n\\n- Select View Database Access History.\\n\\n</Tab>\\n\\n</Tabs>\\n\\n',\n",
       " 'url': 'https://mongodb.com/docs/atlas/access-tracking/',\n",
       " 'format': 'md',\n",
       " 'title': 'View Database Access History'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a document to understand its structure\n",
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Chunk up the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from typing import Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common list of separators for text data\n",
    "separators = [\"\\n\\n\", \"\\n\", \" \", \"\", \"#\", \"##\", \"###\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the `RecursiveCharacterTextSplitter` from LangChain to first split a piece of text on the list of `separators` above.\n",
    "# Then recursively merge them into tokens until the specified chunk size is reached.\n",
    "# For text data, you typically want to keep 1-2 paragraphs (~200 tokens) in a single chunk.\n",
    "# Chunk overlap of 15-20% of the chunk size is recommended to maintain context between chunks.\n",
    "# Pass the `separators` list above as an argument called `separators`\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4\", separators=separators, chunk_size=200, chunk_overlap=30\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://api.python.langchain.com/en/latest/character/langchain_text_splitters.character.RecursiveCharacterTextSplitter.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks(doc: Dict, text_field: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Chunk up a document.\n",
    "\n",
    "    Args:\n",
    "        doc (Dict): Parent document to generate chunks from.\n",
    "        text_field (str): Text field to chunk.\n",
    "\n",
    "    Returns:\n",
    "        List[Dict]: List of chunked documents.\n",
    "    \"\"\"\n",
    "    # Extract the field to chunk from `doc`\n",
    "    text = doc[text_field]\n",
    "    # Split `text` using the appropriate method of the `RecursiveCharacterTextSplitter` class\n",
    "    # NOTE: `text` is a string\n",
    "    chunks = <CODE_BLOCK_1>\n",
    "\n",
    "    # Iterate through `chunks` and for each chunk:\n",
    "    # 1. Create a shallow copy of `doc`, call it `temp`\n",
    "    # 2. Set the `text_field` field in `temp` to the content of the chunk\n",
    "    # 3. Append `temp` to `chunked_data`\n",
    "    chunked_data = []\n",
    "    for chunk in chunks:\n",
    "        temp = doc.copy()\n",
    "        temp[text_field]=chunk\n",
    "        chunked_data.append(temp)\n",
    "\n",
    "    return chunked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_docs = []\n",
    "# Iterate through `docs`, use the `get_chunks` function to chunk up the \"body\" field in the documents, and add the list of chunked documents to `split_docs` initialized above.\n",
    "for doc in docs:\n",
    "    chunks = <CODE_BLOCK_2>\n",
    "    split_docs.extend(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Notice that the length of `split_docs` is greater than the length of `docs` from Step 2 above\n",
    "# This is because each document in `docs` has been split into multiple chunks\n",
    "len(split_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'updated': '2024-05-20T17:30:49.148Z',\n",
       " 'metadata': {'contentType': None,\n",
       "  'productName': 'MongoDB Atlas',\n",
       "  'tags': ['atlas', 'docs'],\n",
       "  'version': None},\n",
       " 'action': 'created',\n",
       " 'sourceName': 'snooty-cloud-docs',\n",
       " 'body': '# View Database Access History\\n\\n- This feature is not available for `M0` free clusters, `M2`, and `M5` clusters. To learn more, see Atlas M0 (Free Cluster), M2, and M5 Limits.\\n\\n- This feature is not supported on Serverless instances at this time. To learn more, see Serverless Instance Limitations.\\n\\n## Overview\\n\\nAtlas parses the MongoDB database logs to collect a list of authentication requests made against your clusters through the following methods:\\n\\n- `mongosh`\\n\\n- Compass\\n\\n- Drivers\\n\\nAuthentication requests made with API Keys through the Atlas Administration API are not logged.\\n\\nAtlas logs the following information for each authentication request within the last 7 days:\\n\\n<table>\\n<tr>\\n<th id=\"Field\">\\nField\\n\\n</th>\\n<th id=\"Description\">\\nDescription\\n\\n</th>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nTimestamp',\n",
       " 'url': 'https://mongodb.com/docs/atlas/access-tracking/',\n",
       " 'format': 'md',\n",
       " 'title': 'View Database Access History'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview a chunked document to understand its structure\n",
    "# Note that the structure looks similar to the original docs, except the `body` field now contains smaller chunks of text\n",
    "split_docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Generate embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may see a warning upon running this cell. You can ignore it.\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80d1bfdfc4644e33aea4c5178bc58a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/385 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f4b323a4bd4ca8be7e1cfe5171245a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/68.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78ba57ec66cb4baf875d6909a75826a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/57.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca52d02ef33a4326a7b4ef079aaecf08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/583 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb678160e767470db9c4ce81cd49c23e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/66.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7806896a36fd4c89944961da63b05305",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dcb6983dc82412996a45d400401616b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c039c81d0df4987b3cb57c2f530d49d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74d3ce398f684bda89d100cf59c661ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8404aacec544286b0e398474c67edb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the `gte-small` model using the Sentence Transformers library\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-small\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://huggingface.co/thenlper/gte-small#usage (See \"Use with sentence-transformers\" under Usage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function that takes a piece of text (`text`) as input, embeds it using the `embedding_model` instantiated above and returns the embedding as a list\n",
    "# An array can be converted to a list using the `tolist()` method\n",
    "def get_embedding(text: str) -> List[float]:\n",
    "    \"\"\"\n",
    "    Generate the embedding for a piece of text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to embed.\n",
    "\n",
    "    Returns:\n",
    "        List[float]: Embedding of the text as a list.\n",
    "    \"\"\"\n",
    "    embedding = <CODE_BLOCK_3>\n",
    "    return embedding.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:05<00:00, 18.60it/s]\n"
     ]
    }
   ],
   "source": [
    "docs_with_embeddings = []\n",
    "# Add an `embedding` field to each dictionary in `split_docs`\n",
    "# The `embedding` field should correspond to the embedding of the value of the `body` field\n",
    "# Use the `get_embedding` function defined above to generate the embedding\n",
    "# Append the updated dictionaries to `embedded_docs` initialized above.\n",
    "for doc in tqdm(split_docs):\n",
    "    <CODE_BLOCK_4>\n",
    "    docs_with_embeddings.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check that the length of `embedded_docs` is the same as that of `split_docs`\n",
    "len(docs_with_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Ingest data into MongoDB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `DB_NAME` database.\n",
    "# Use the `mongodb_client` instantiated in Step 1.\n",
    "db = <CODE_BLOCK_5>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://pymongo.readthedocs.io/en/stable/tutorial.html#getting-a-collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the `COLLECTION_NAME` collection.\n",
    "# Use the `db` and collection name defined above.\n",
    "collection = <CODE_BLOCK_6>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeleteResult({'n': 0, 'electionId': ObjectId('7fffffff0000000000000003'), 'opTime': {'ts': Timestamp(1745417455, 1), 't': 3}, 'ok': 1.0, '$clusterTime': {'clusterTime': Timestamp(1745417455, 1), 'signature': {'hash': b'\\x1bG\\xe1\\xcd\\xdd\\xf74\\xf8B\\xafP\\x9a\\xb3\\xc3W?\\xb1\\xa5K\\x89', 'keyId': 7496241214685970439}}, 'operationTime': Timestamp(1745417455, 1)}, acknowledged=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bulk delete all existing records from the collection defined above\n",
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://pymongo.readthedocs.io/en/stable/examples/bulk.html#bulk-insert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingested 107 documents into the knowledge_base collection.\n"
     ]
    }
   ],
   "source": [
    "# Bulk insert `embedded_docs` into the collection defined above -- should be a one-liner\n",
    "<CODE_BLOCK_7>\n",
    "\n",
    "print(f\"Ingested {collection.count_documents({})} documents into the {COLLECTION_NAME} collection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Create a vector search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vector index definition specifying:\n",
    "# path: Path to the embeddings field\n",
    "# numDimensions: Number of embedding dimensions- depends on the embedding model used\n",
    "# similarity: Similarity metric. One of cosine, euclidean, dotProduct.\n",
    "model = {\n",
    "    \"name\": ATLAS_VECTOR_SEARCH_INDEX_NAME,\n",
    "    \"type\": \"vectorSearch\",\n",
    "    \"definition\": {\n",
    "        \"fields\": [\n",
    "            {\n",
    "                \"type\": \"vector\",\n",
    "                \"path\": \"embedding\",\n",
    "                \"numDimensions\": 384,\n",
    "                \"similarity\": \"cosine\",\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.create_search_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vector_index'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a vector search index with the above definition for the `collection` collection\n",
    "<CODE_BLOCK_8>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': '6808f51a24c10c1eaa40d170', 'name': 'vector_index', 'type': 'vectorSearch', 'status': 'READY', 'queryable': True, 'latestVersion': 0, 'latestDefinition': {'fields': [{'type': 'vector', 'path': 'embedding', 'numDimensions': 384, 'similarity': 'cosine'}]}}\n"
     ]
    }
   ],
   "source": [
    "# Verify the index is in READY status\n",
    "results = list(collection.list_search_indexes())\n",
    "\n",
    "for index in results:\n",
    "    print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Perform vector search on your data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a vector search function\n",
    "\n",
    "📚 https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Basic Example\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to retrieve relevant documents for a user query using vector search\n",
    "def vector_search(user_query: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Retrieve relevant documents for a user query using vector search.\n",
    "\n",
    "    Args:\n",
    "    user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of matching documents.\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate embedding for the `user_query` using the `get_embedding` function defined in Step 4\n",
    "    query_embedding = <CODE_BLOCK_9>\n",
    "\n",
    "    # Define an aggregation pipeline consisting of a $vectorSearch stage, followed by a $project stage\n",
    "    # Set the number of candidates to 150 and only return the top 5 documents from the vector search\n",
    "    # In the $project stage, exclude the `_id` field and include only the `body` field and `vectorSearchScore`\n",
    "    # NOTE: Use variables defined previously for the `index`, `queryVector` and `path` fields in the $vectorSearch stage\n",
    "    pipeline = <CODE_BLOCK_10>\n",
    "\n",
    "    # Execute the aggregation `pipeline` and store the results in `results`\n",
    "    results = <CODE_BLOCK_11>\n",
    "    return list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run vector search queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'body': '# Backup and Restore Sharded Clusters\\n\\nThe following tutorials describe backup and restoration for sharded clusters:\\n\\nTo use `mongodump` and `mongorestore` as a backup strategy for sharded clusters, you must stop the sharded cluster balancer and use the `fsync` command or the `db.fsyncLock()` method on `mongos` to block writes on the cluster during backups.\\n\\nSharded clusters can also use one of the following coordinated backup and restore processes, which maintain the atomicity guarantees of transactions across shards:\\n\\n- MongoDB Atlas\\n\\n- MongoDB Cloud Manager\\n\\n- MongoDB Ops Manager\\n\\nUse file system snapshots back up each component in the sharded cluster individually. The procedure involves stopping the cluster balancer. If your system configuration allows file system backups, this might be more efficient than using MongoDB tools.\\n\\nCreate backups using `mongodump` to back up each component in the cluster individually.',\n",
       "  'score': 0.9431126117706299},\n",
       " {'body': 'Create backups using `mongodump` to back up each component in the cluster individually.\\n\\nLimit the operation of the cluster balancer to provide a window for regular backup operations.\\n\\nAn outline of the procedure and consideration for restoring an *entire* sharded cluster from backup.',\n",
       "  'score': 0.9327979683876038},\n",
       " {'body': \"# Configuration and Maintenance\\n\\nThis section describes routine management operations, including updating your MongoDB deployment's configuration.\\n\\nOutlines common MongoDB configurations and examples of best-practice configurations for common use cases.\\n\\nUpgrade a MongoDB deployment to a different patch release within the same major release series.\\n\\nStart, configure, and manage running `mongod` process.\\n\\nStop in progress MongoDB client operations using `db.killOp()` and `maxTimeMS()`.\\n\\nArchive the current log files and start new ones.\",\n",
       "  'score': 0.9310877323150635},\n",
       " {'body': '## Full Time Diagnostic Data Capture\\n\\nTo help MongoDB engineers analyze server behavior, `mongod` and `mongos` processes include a Full Time Diagnostic Data Capture (FTDC) mechanism. FTDC is enabled by default. Due to its importance in debugging deployments, FTDC thread failures are fatal and stop the parent `mongod` or `mongos` process.\\n\\nFTDC data files are compressed and not human-readable. They inherit the same file access permissions as the MongoDB data files. Only users with access to FTDC data files can transmit the FTDC data.\\n\\nMongoDB engineers cannot access FTDC data without explicit permission and assistance from system owners or operators.\\n\\nFTDC data **never** contains any of the following information:\\n\\n- Samples of queries, query predicates, or query results\\n\\n- Data sampled from any end-user collection or index\\n\\n- System or MongoDB user credentials or security certificates',\n",
       "  'score': 0.9286066293716431},\n",
       " {'body': \"# Create a MongoDB Deployment\\n\\nYou can create a free tier MongoDB deployment on MongoDB Atlas to store and manage your data. MongoDB Atlas hosts and manages your MongoDB database in the cloud.\\n\\n## Create a Free MongoDB deployment on Atlas\\n\\nComplete the Get Started with Atlas guide to set up a new Atlas account and load sample data into a new free tier MongoDB deployment.\\n\\n## Save your Credentials\\n\\nAfter you create your database user, save that user's username and password to a safe location for use in an upcoming step.\\n\\nAfter you complete these steps, you have a new free tier MongoDB deployment on Atlas, database user credentials, and sample data loaded in your database.\\n\\nIf you run into issues on this step, ask for help in the MongoDB Community Forums or submit feedback by using the Rate this page tab on the right or bottom right side of this page.\",\n",
       "  'score': 0.9270493984222412}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'body': 'The name must be unique within an organization.\\n\\n### Add team members.\\n\\nTo add existing organization users to the team, click in the Add Members box and either start typing their Cloud Manager username or click on the name of a user that appears in the combo box.\\n\\n### Click Create Team.\\n\\n</Tab>\\n\\n</Tabs>\\n\\n## View Teams\\n\\n<Tabs>\\n\\n<Tab name=\"Atlas CLI\">\\n\\nTo list all teams in your organization using the Atlas CLI, run the following command:\\n\\n```sh\\n\\natlas teams list [options]\\n\\n```\\n\\nTo return the details for the team you specify using the Atlas CLI, run the following command:\\n\\n```sh\\n\\natlas teams describe [options]\\n\\n```\\n\\nTo learn more about the syntax and parameters for the previous commands, see the Atlas CLI documentation for atlas teams list and atlas teams describe.\\n\\n- Install the Atlas CLI\\n\\n- Connect to the Atlas CLI\\n\\n</Tab>',\n",
       "  'score': 0.9075105786323547},\n",
       " {'body': '```sh\\n\\natlas teams create <name> [options]\\n\\n```\\n\\nTo learn more about the command syntax and parameters, see the Atlas CLI documentation for atlas teams create.\\n\\n- Install the Atlas CLI\\n\\n- Connect to the Atlas CLI\\n\\nTo add users to your team, see Add Team Members.\\n\\n</Tab>\\n\\n<Tab name=\"Atlas UI\">\\n\\nTo create a team using the Atlas UI:\\n\\n### Navigate to the Access Manager page for your organization.\\n\\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\\n\\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\\n\\n### Click Create Team.\\n\\n### Enter a name for the team in the Name Your Team box.\\n\\nThe name must be unique within an organization.\\n\\n### Add team members.',\n",
       "  'score': 0.9026548862457275},\n",
       " {'body': '</Tab>\\n\\n</Tabs>\\n\\n## Rename a Team\\n\\nYou can\\'t rename a team using the Atlas CLI.\\n\\n### Navigate to the Access Manager page for your organization.\\n\\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.\\n\\n- Click Access Manager in the sidebar, or click Access Manager in the navigation bar, then click your organization.\\n\\n### Click the Teams tab.\\n\\n### Rename the team.\\n\\nFor the team you want to rename:\\n\\n- Click the ellipsis (`...`) button under the Actions column.\\n\\n- Click Rename Team.\\n\\n- Enter a new name for the team.\\n\\n  The team name must be unique within the organization.\\n\\n- Click Rename Team.\\n\\n## Delete a Team\\n\\n<Tabs>\\n\\n<Tab name=\"Atlas CLI\">\\n\\nTo delete one team from your organization using the Atlas CLI, run the following command:\\n\\n```sh',\n",
       "  'score': 0.9004052877426147},\n",
       " {'body': '</th>\\n<th id=\"Description\">\\nDescription\\n\\n</th>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nTimestamp\\n\\n</td>\\n<td headers=\"Description\">\\nThe date and time of the authentication request.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nUsername\\n\\n</td>\\n<td headers=\"Description\">\\nThe username associated with the database user who made the authentication request.\\n\\nFor LDAP usernames, the UI displays the resolved LDAP name. Hover over the name to see the full LDAP username.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nIP Address\\n\\n</td>\\n<td headers=\"Description\">\\nThe IP address of the machine that sent the authentication request.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nHost\\n\\n</td>\\n<td headers=\"Description\">\\nThe target server that processed the authentication request.\\n\\n</td>\\n</tr>\\n<tr>\\n<td headers=\"Field\">\\nAuthentication Source',\n",
       "  'score': 0.8969519138336182},\n",
       " {'body': '- Install the Atlas CLI\\n\\n- Connect to the Atlas CLI\\n\\n</Tab>\\n\\n<Tab name=\"Atlas UI\">\\n\\n### Expand the Organizations menu in the navigation bar.\\n\\n### Click View All Organizations.\\n\\n</Tab>\\n\\n</Tabs>\\n\\n## Leave an Organization\\n\\nTo leave an organization, at least another user must exist as an Owner for the organization.\\n\\n### View all of your organizations.\\n\\n- Expand the Organizations menu in the navigation bar.\\n\\n- Click View All Organizations.\\n\\n### Leave organization.\\n\\nFor the organization you wish to leave, click its Leave button to bring up the Leave Organization dialog.\\n\\n### Click Leave Organization in the Leave Organization dialog.\\n\\n## Rename an Organization\\n\\nYou must have the `Organization Owner` role for an organization to rename it.\\n\\n### Navigate to the Settings page for your organization.\\n\\n- If it is not already displayed, select your desired organization from the  Organizations menu in the navigation bar.',\n",
       "  'score': 0.8960856795310974}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_search(\"What is my name?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦹‍♀️ Combine pre-filtering with vector search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter for documents where the product name is `MongoDB Atlas`\n",
    "\n",
    "📚 https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-type/#about-the-filter-type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the vector search index `model` from Step 6 to include the `metadata.productName` field as a `filter` field\n",
    "model = <CODE_BLOCK_12>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update vector search index\n",
    "collection.update_search_index(\n",
    "    name=ATLAS_VECTOR_SEARCH_INDEX_NAME, definition=model[\"definition\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Check that the index update is complete before proceeding. To do so, ensure that the status of the index shows \"Ready\" in the Atlas UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the user query\n",
    "query_embedding = get_embedding(\n",
    "    \"What are some best practices for data backups in MongoDB?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://www.mongodb.com/docs/atlas/atlas-vector-search/vector-search-stage/#ann-examples (Refer to the \"Filter Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the $vectorSearch stage of the aggregation pipeline defined previously to include a filter for documents where the `metadata.productName` field has the value \"MongoDB Atlas\"\n",
    "pipeline = <CODE_BLOCK_13>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the aggregation pipeline and view the results\n",
    "results = collection.aggregate(pipeline)\n",
    "list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter on documents which have been updated on or after `2024-05-19` and where the content type is `Tutorial`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the vector search index `model` from Step 6 to include `metadata.contentType` and `updated` as `filter` fields\n",
    "model = <CODE_BLOCK_14>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update vector search index\n",
    "collection.update_search_index(\n",
    "    name=ATLAS_VECTOR_SEARCH_INDEX_NAME, definition=model[\"definition\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Check that the index update is complete before proceeding. To do so, ensure that the status of the index shows \"Ready\" in the Atlas UI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed the user query\n",
    "query_embedding = get_embedding(\n",
    "    \"What are some best practices for data backups in MongoDB?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the $vectorSearch stage of the aggregation pipeline defined previously to include a filter for documents where\n",
    "# the `metadata.contentType` field has the value \"Tutorial\"\n",
    "# AND\n",
    "# the `updated` field is greater than or equal to \"2024-05-19\"\n",
    "pipeline = <CODE_BLOCK_15>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the aggregation pipeline and view the results\n",
    "results = collection.aggregate(pipeline)\n",
    "list(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Build the RAG application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to create the chat prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the user prompt for our RAG application\n",
    "def create_prompt(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a chat prompt that includes the user query and retrieved context.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "        str: The chat prompt string.\n",
    "    \"\"\"\n",
    "    # Retrieve the most relevant documents for the `user_query` using the `vector_search` function defined in Step 7\n",
    "    context = <CODE_BLOCK_16>\n",
    "    # Join the retrieved documents into a single string, where each document is separated by two new lines (\"\\n\\n\")\n",
    "    context = \"\\n\\n\".join([doc.get('body') for doc in context])\n",
    "    # Prompt consisting of the question and relevant context to answer it\n",
    "    prompt = f\"Answer the question based only on the following context. If the context is empty, say I DON'T KNOW\\n\\nContext:\\n{context}\\n\\nQuestion:{user_query}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to answer user queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to answer user queries\n",
    "def generate_answer(user_query: str) -> None:\n",
    "    \"\"\"\n",
    "    Generate an answer to the user query.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The user's query string.\n",
    "    \"\"\"\n",
    "    # Use the `create_prompt` function above to create a chat prompt\n",
    "    prompt = <CODE_BLOCK_17>\n",
    "    # Format the message to the LLM in the format {\"role\": <role_value>, \"content\": <content_value>}\n",
    "    # The role value for user messages must be \"user\"\n",
    "    # Use the `prompt` created above to populate the `content` field in the chat message\n",
    "    messages = []\n",
    "    messages.append(<CODE_BLOCK_18>)\n",
    "    # Send the chat messages to a serverless function to get back an LLM response\n",
    "    response = requests.post(url=SERVERLESS_URL, json={\"task\": \"completion\", \"data\": messages})\n",
    "    # Print the final answer\n",
    "    print(response.json()[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the RAG application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DON'T KNOW\n",
      "\n",
      "The given context does not contain any information about cures for hangovers. The context appears to be about MongoDB database backups and alerts, which is unrelated to the question asked.\n"
     ]
    }
   ],
   "source": [
    "generate_answer(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I DON'T KNOW\n",
      "\n",
      "The given context does not contain any question that you asked me. The context provides information about using CodeWhisperer, requesting suggestions manually, and some JSON data related to reviews. There is no previous question mentioned in this context.\n"
     ]
    }
   ],
   "source": [
    "# Notice that the LLM does not remember the conversation history at this stage\n",
    "generate_answer(\"What did I just ask you?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🦹‍♀️ Re-rank retrieved results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import CrossEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_model = CrossEncoder(\"mixedbread-ai/mxbai-rerank-xsmall-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://huggingface.co/mixedbread-ai/mxbai-rerank-xsmall-v1#quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a re-ranking step to the following function\n",
    "def create_prompt(user_query: str) -> str:\n",
    "    \"\"\"\n",
    "    Create a chat prompt that includes the user query and retrieved context.\n",
    "\n",
    "    Args:\n",
    "        user_query (str): The user's query string.\n",
    "\n",
    "    Returns:\n",
    "        str: The chat prompt string.\n",
    "    \"\"\"\n",
    "    # Retrieve the most relevant documents for the `user_query` using the `vector_search` function defined in Step 7\n",
    "    context = vector_search(user_query)\n",
    "    # Extract the \"body\" field from each document in `context`\n",
    "    documents = [d.get(\"body\") for d in context]\n",
    "    # Use the `rerank_model` instantiated above to re-rank `documents`\n",
    "    # Set the `top_k` argument to 5 \n",
    "    reranked_documents = <CODE_BLOCK_19>\n",
    "    # Join the re-ranked documents into a single string, where each document is separated by two new lines (\"\\n\\n\")\n",
    "    context = \"\\n\\n\".join([d.get(\"text\", \"\") for d in reranked_documents])\n",
    "    # Prompt consisting of the question and relevant context to answer it\n",
    "    prompt = f\"Answer the question based only on the following context. If the context is empty, say I DON'T KNOW\\n\\nContext:\\n{context}\\n\\nQuestion:{user_query}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note the impact of re-ranking on the generated answer\n",
    "# You might not see a difference in this example since we are only re-ranking 5 documents\n",
    "# In practice, you would send a larger number of documents to the re-ranker, and get the top few AFTER reranking\n",
    "generate_answer(\"What are some best practices for data backups in MongoDB?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Add memory to the RAG application\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_collection = mongodb_client[DB_NAME][\"chat_history\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.create_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'session_id_1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an index on the key `session_id` for the `history_collection` collection\n",
    "<CODE_BLOCK_20>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to store chat messages in MongoDB\n",
    "\n",
    "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/collection.html#pymongo.collection.Collection.insert_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_chat_message(session_id: str, role: str, content: str) -> None:\n",
    "    \"\"\"\n",
    "    Store a chat message in a MongoDB collection.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session ID of the message.\n",
    "        role (str): Role for the message. One of `system`, `user` or `assistant`.\n",
    "        content (str): Content of the message.\n",
    "    \"\"\"\n",
    "    # Create a message object with `session_id`, `role`, `content` and `timestamp` fields\n",
    "    # `timestamp` should be set the current timestamp\n",
    "    message = {\n",
    "        \"session_id\": session_id,\n",
    "        \"role\": role,\n",
    "        \"content\": content,\n",
    "        \"timestamp\": datetime.now(),\n",
    "    }\n",
    "    # Insert the `message` into the `history_collection` collection\n",
    "    <CODE_BLOCK_21>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to retrieve chat history from MongoDB\n",
    "\n",
    "📚 https://pymongo.readthedocs.io/en/stable/api/pymongo/cursor.html#pymongo.cursor.Cursor.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_session_history(session_id: str) -> List:\n",
    "    \"\"\"\n",
    "    Retrieve chat message history for a particular session.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session ID to retrieve chat message history for.\n",
    "\n",
    "    Returns:\n",
    "        List: List of chat messages.\n",
    "    \"\"\"\n",
    "    # Query the `history_collection` collection for documents where the \"session_id\" field has the value of the input `session_id`\n",
    "    # Sort the results in increasing order of the values in `timestamp` field\n",
    "    cursor = <CODE_BLOCK_22>\n",
    "\n",
    "    if cursor:\n",
    "        # Iterate through the cursor and extract the `role` and `content` field from each entry\n",
    "        # Then format each entry as: {\"role\": <role_value>, \"content\": <content_value>}\n",
    "        messages = [{\"role\": msg[\"role\"], \"content\": msg[\"content\"]} for msg in cursor]\n",
    "    else:\n",
    "        # If cursor is empty, return an empty list\n",
    "        messages = []\n",
    "\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle chat history in the `generate_answer` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(session_id: str, user_query: str) -> None:\n",
    "    \"\"\"\n",
    "    Generate an answer to the user's query taking chat history into account.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session ID to retrieve chat history for.\n",
    "        user_query (str): The user's query string.\n",
    "    \"\"\"\n",
    "    # Initialize list of messages to pass to the chat completion model\n",
    "    messages = []\n",
    "\n",
    "    # Retrieve documents relevant to the user query and convert them to a single string\n",
    "    context = vector_search(user_query)\n",
    "    context = \"\\n\\n\".join([d.get(\"body\", \"\") for d in context])\n",
    "    # Create a system prompt containing the retrieved context\n",
    "    system_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Answer the question based only on the following context. If the context is empty, say I DON'T KNOW\\n\\nContext:\\n{context}\",\n",
    "    }\n",
    "    # Append the system prompt to the `messages` list\n",
    "    messages.append(system_message)\n",
    "\n",
    "    # Use the `retrieve_session_history` function to retrieve message history from MongoDB for the session ID `session_id` \n",
    "    # And add all messages in the message history to the `messages` list \n",
    "    message_history = <CODE_BLOCK_23>\n",
    "    messages.extend(message_history)\n",
    "\n",
    "    # Format the user query in the format {\"role\": <role_value>, \"content\": <content_value>}\n",
    "    # The role value for user messages must be \"user\"\n",
    "    # And append the user message to the `messages` list\n",
    "    user_message = <CODE_BLOCK_24>\n",
    "    messages.append(user_message)\n",
    "\n",
    "    # Send the chat messages to a serverless function to get back an LLM response\n",
    "    response = requests.post(url=SERVERLESS_URL, json={\"task\": \"completion\", \"data\": messages})\n",
    "\n",
    "    # Extract the answer from the response\n",
    "    answer = response.json()[\"text\"]\n",
    "\n",
    "    # Use the `store_chat_message` function to store the user message and also the generated answer in the message history collection\n",
    "    # The role value for user messages is \"user\", and \"assistant\" for the generated answer\n",
    "    <CODE_BLOCK_25>\n",
    "\n",
    "    print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the given context, some best practices for data backups in MongoDB sharded clusters include:\n",
      "\n",
      "1. Stopping the sharded cluster balancer before performing backups.\n",
      "\n",
      "2. Using the fsync command or db.fsyncLock() method on mongos to block writes during backups when using mongodump and mongorestore.\n",
      "\n",
      "3. Using coordinated backup and restore processes that maintain transaction atomicity across shards, such as MongoDB Atlas, MongoDB Cloud Manager, or MongoDB Ops Manager.\n",
      "\n",
      "4. Using file system snapshots to back up each component of the sharded cluster individually, if the system configuration allows it.\n",
      "\n",
      "5. Using mongodump to back up each component of the cluster individually.\n",
      "\n",
      "6. Limiting the operation of the cluster balancer to provide a window for regular backup operations.\n",
      "\n",
      "7. For full cluster backups, following a specific procedure to restore the entire sharded cluster from backup.\n",
      "\n",
      "The context also mentions that it's important to consider the atomicity guarantees of transactions across shards when choosing a backup method.\n"
     ]
    }
   ],
   "source": [
    "generate_answer(\n",
    "    session_id=\"1\",\n",
    "    user_query=\"What are some best practices for data backups in MongoDB?\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize for the confusion in my previous response. You asked:\n",
      "\n",
      "\"What are some best practices for data backups in MongoDB?\"\n",
      "\n",
      "However, after reviewing the given context again, I realize that the context does not contain any information about MongoDB backup best practices. The context mainly discusses CodeWhisperer usage and some MongoDB document examples. \n",
      "\n",
      "Given that there is no relevant information in the provided context to answer your specific question about MongoDB backup best practices, the correct response should have been:\n",
      "\n",
      "I DON'T KNOW\n"
     ]
    }
   ],
   "source": [
    "generate_answer(\n",
    "    session_id=\"1\",\n",
    "    user_query=\"What did I just ask you?\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
